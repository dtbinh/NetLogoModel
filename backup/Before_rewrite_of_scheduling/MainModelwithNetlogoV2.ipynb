{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "C:\\Users\\Yanjie\\Anaconda\\lib\\site-packages\\theano\\tensor\\signal\\downsample.py:5: UserWarning: downsample module has been moved to the pool module.\n",
      "  warnings.warn(\"downsample module has been moved to the pool module.\")\n"
     ]
    }
   ],
   "source": [
    "# import functions\n",
    "# version 2: did not use imputation. just ML directly \n",
    "\n",
    "# parameters:\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import codecs\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from fancyimpute import BiScaler, KNN, NuclearNormMinimization, SoftImpute\n",
    "from sklearn.preprocessing import StandardScaler                 #normalising features\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.svm import SVC, SVR\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor\n",
    "from sknn import mlp\n",
    "\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed=10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from py4j.java_gateway import JavaGateway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# set up connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gw = JavaGateway() # New gateway connection\n",
    "bridge = gw.entry_point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load netlogo model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Path to the model:\n",
    "models_path = \"D:/Work/PhD/Github/NetLogoModel/\"\n",
    "model_name = \"PhD_InitialModelV2.nlogo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "modelLocation = models_path + model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:/Work/PhD/Github/NetLogoModel/PhD_InitialModelV2.nlogo'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelLocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bridge.openModel(modelLocation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run one iteration of the model, one command at a time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bridge.command(\"set grid-size 21\")\n",
    "bridge.command(\"set nb-people 1\")\n",
    "bridge.command(\"set Show_Names_Nodes? False\")\n",
    "bridge.command(\"set Show_Names_people? False\")\n",
    "bridge.command(\"set car-speed 1\")\n",
    "bridge.command(\"set mobiletowerdata? True\")\n",
    "bridge.command(\"set socialmedia_data? True\")\n",
    "bridge.command(\"set grids_covered_vector 10\")\n",
    "bridge.command(\"set avg_num_calls_perday 100\")\n",
    "bridge.command(\"set avg_call_duration_mins 2\")\n",
    "\n",
    "bridge.command(\"random-seed 0\")\n",
    "bridge.command(\"setup\")\n",
    "bridge.command(\"repeat 1440 [go]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bridge.command(\"repeat 144000 [go]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Have the model report results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!head -n 15 ./agentdata.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!head -n 15 ./mobiletowers.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initiating the netlogo model\n",
    "# and run it for the first 10 days\n",
    "def model_init():\n",
    "    bridge.command(\"set grid-size 21\")\n",
    "    bridge.command(\"set nb-people 1\")\n",
    "    bridge.command(\"set Show_Names_Nodes? False\")\n",
    "    bridge.command(\"set Show_Names_people? False\")\n",
    "    bridge.command(\"set car-speed 1\")\n",
    "    bridge.command(\"set mobiletowerdata? True\")\n",
    "    bridge.command(\"set socialmedia_data? True\")\n",
    "    bridge.command(\"set grids_covered_vector 5\")\n",
    "    bridge.command(\"set avg_num_calls_perday 10\")\n",
    "    bridge.command(\"set avg_call_duration_mins 2\")\n",
    "    bridge.command(\"random-seed 0\")\n",
    "    bridge.command(\"setup\")\n",
    "    #bridge.command(\"repeat \" + str(ini_day) + \" [go]\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import simuated data\n",
    "# using function as the file can be closed automatically\n",
    "def rawimport(path, columnname):\n",
    "    agentdata = pd.read_csv(path, delimiter=' ', header=None, names=columnname)\n",
    "    agentdata = agentdata.drop(labels=\"todrop\", axis=1)\n",
    "    return agentdata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# run NL model; \n",
    "def run_NL(mob_call):\n",
    "    bridge.command(mob_call)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_input():\n",
    "    path = './agentdata.txt'\n",
    "    columnname = [\"todrop\", \"acc_time\", \"day\", \"minute\", \"pid\", \"zone\", \"status\", \"xcor\", \"ycor\", \"tid\"]\n",
    "    agentdata = rawimport(path, columnname)\n",
    "\n",
    "    path = './mobiletowers.txt'\n",
    "    columnname = [\"todrop\", \"acc_time\", \"day\", \"minute\", \"pid\", \"tpid\", \"tzone\", \"radius\", \"tid\", \"txcor\", \"tycor\"]\n",
    "    mobiledata = rawimport(path, columnname)\n",
    "    # leave the last n day(s) out for testing purpose\n",
    "\n",
    "    # mobiledata_ML = mobiledata[mobiledata['day'] <= (mobiledata['day'].max() - last_n)]\n",
    "    mobiledata_ML = mobiledata.drop('radius', axis = 1)\n",
    "    mobiledata_ML.drop('acc_time', axis=1, inplace=True)\n",
    "    mobiledata_ML.drop('tid', axis=1, inplace=True)\n",
    "    mobiledata_ML.drop('txcor', axis=1, inplace=True)\n",
    "    mobiledata_ML.drop('tycor', axis=1, inplace=True)\n",
    "    \n",
    "    agentdata.drop('acc_time', axis=1, inplace=True)\n",
    "#     mobiledata_ML = pd.concat([mobiledata_pre, mobiledata_new])\n",
    "#     mobiledata_ML = mobiledata_ML.reset_index(drop=True)\n",
    "    \n",
    "#     agentdata = pd.concat([agentdata_pre, agentdata_new])\n",
    "#     agentdata = agentdata.reset_index(drop=True)\n",
    "    \n",
    "    return (agentdata, mobiledata_ML)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ReturnedValue(object):\n",
    "    def __init__(self, clf1, clf2, clf3, clf4):\n",
    "        self.clf1 = clf1\n",
    "        self.clf2 = clf2\n",
    "        self.clf3 = clf3\n",
    "        self.clf4 = clf4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def NL_ML(mobiledata_ML, day_new, traintest_pre):\n",
    "    # prepare for ML\n",
    "    \n",
    "    # need to keep previous training/testing samples, otherwise results flactuates\n",
    "    \n",
    "    mobiledata_new = mobiledata_ML[mobiledata_ML['day']>=day_new]\n",
    "    \n",
    "    X_new = mobiledata_new.drop('tzone', axis=1)\n",
    "    y_new = mobiledata_new['tzone']\n",
    "    trainX_new, testX_new, trainY_new, testY_new = train_test_split(X_new, y_new, random_state = 10)\n",
    "        \n",
    "    trainX = pd.concat([traintest_pre[0], trainX_new])\n",
    "    testX = pd.concat([traintest_pre[1], testX_new])\n",
    "    trainY = pd.concat([traintest_pre[2], trainY_new])\n",
    "    testY = pd.concat([traintest_pre[3], testY_new])\n",
    "    \n",
    "    X = mobiledata_ML.drop('tzone', axis=1)\n",
    "    y = mobiledata_ML['tzone']\n",
    "    \n",
    "    # knn\n",
    "    clf_knn = KNeighborsClassifier(n_neighbors=1).fit(trainX, trainY)\n",
    "    pred_knn = clf_knn.predict(testX)\n",
    "    #print roc_auc_score(testY, pred_knn)\n",
    "    AC_knn = accuracy_score(testY, pred_knn)\n",
    "    RC_knn = recall_score(testY, pred_knn, average=None).mean()\n",
    "    CF_knn = confusion_matrix(testY, pred_knn)\n",
    "    CV_knn = cross_val_score(clf_knn, X, y, cv=3)\n",
    "    ## using ridge regression\n",
    "    clf_rdg = RidgeClassifier(alpha=1).fit(trainX,trainY)\n",
    "    pred_rdg = clf_rdg.predict(testX)\n",
    "    AC_rdg = accuracy_score(testY, pred_rdg)\n",
    "    RC_rdg = recall_score(testY, pred_rdg, average=None).mean()  \n",
    "    CF_rdg =  confusion_matrix(testY, pred_rdg)\n",
    "    CV_rdg = cross_val_score(clf_rdg, X, y, cv=3)\n",
    "    ## using RF\n",
    "    clf_rf = RandomForestClassifier(n_estimators=100, max_depth=100)\n",
    "    clf_rf.fit(trainX, trainY)\n",
    "    pred_rf = clf_rf.predict(testX)\n",
    "    AC_rf = accuracy_score(testY, pred_rf)\n",
    "    RC_rf = recall_score(testY, pred_rf, average=None).mean()   \n",
    "    CF_rf = confusion_matrix(testY, pred_rf)\n",
    "    CV_rf = cross_val_score(clf_rf, X, y, cv=3)\n",
    "    ## using GBDT\n",
    "    clf_gb = GradientBoostingClassifier(n_estimators=100, max_depth=3)\n",
    "    clf_gb.fit(trainX, trainY)\n",
    "    pred_gb = clf_gb.predict(testX)\n",
    "    AC_gb = accuracy_score(testY, pred_gb)\n",
    "    RC_gb = recall_score(testY, pred_gb, average=None).mean()  \n",
    "    CF_gb = confusion_matrix(testY, pred_gb)\n",
    "    CV_gb = cross_val_score(clf_gb, X, y, cv=3)\n",
    "    \n",
    "    trained_clf = [clf_knn, clf_rdg, clf_rf, clf_gb]\n",
    "    trained_CV = [CV_knn, CV_rdg, CV_rf, CV_gb]\n",
    "    trained_RC = [RC_knn, RC_rdg, RC_rf, RC_gb]\n",
    "    trained_CM = [CF_knn, CF_rdg, CF_rf, CF_gb]\n",
    "    trained_AC = [AC_knn, AC_rdg, AC_rf, AC_gb]\n",
    "    traintest = [trainX, testX, trainY, testY]\n",
    "    \n",
    "    return (trained_clf, trained_CV, trained_RC, trained_CM, trained_AC, traintest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pred_agent(trained_clf, agentdata, last_n):\n",
    "    last_minutes = last_n * (-1440)\n",
    "    pred_X = agentdata[last_minutes:].iloc[:,0:3]\n",
    "    pred_X['tpid'] = 0\n",
    "    pred_X['day'] = pred_X['day'] + 1\n",
    "#    pred_X['acc_time'] = pred_X['acc_time'] + 1440\n",
    "    pred_y = agentdata[last_minutes:].iloc[:,3]\n",
    "    \n",
    "\n",
    "    pred_knn = trained_clf[0].predict(pred_X)\n",
    "    #print roc_auc_score(testY, pred_knn)\n",
    "    knn_AC = accuracy_score(pred_y, pred_knn)\n",
    "    knn_RC = recall_score(pred_y, pred_knn, average='macro')\n",
    "    knn_CM = confusion_matrix(pred_y, pred_knn)\n",
    "\n",
    "    ## using ridge regression\n",
    "    pred_rdg = trained_clf[1].predict(pred_X)\n",
    "    rdg_AC = accuracy_score(pred_y, pred_rdg)\n",
    "    rdg_RC = recall_score(pred_y, pred_rdg, average='macro')  \n",
    "    rdg_CM = confusion_matrix(pred_y, pred_rdg)\n",
    "\n",
    "    ## using RF\n",
    "    pred_rf = trained_clf[2].predict(pred_X)\n",
    "    rf_AC = accuracy_score(pred_y, pred_rf)\n",
    "    rf_RC = recall_score(pred_y, pred_rf, average='macro')  \n",
    "    rf_CM = confusion_matrix(pred_y, pred_rf)\n",
    "\n",
    "    ## using GBDT\n",
    "    pred_gb = trained_clf[3].predict(pred_X)\n",
    "    gb_AC = accuracy_score(pred_y, pred_gb)\n",
    "    gb_RC = recall_score(pred_y, pred_gb, average='macro')  \n",
    "    gb_CM = confusion_matrix(pred_y, pred_gb)\n",
    "    \n",
    "    pr_RC = [knn_RC, rdg_RC, rf_RC, gb_RC]\n",
    "    pr_CM = [knn_CM, rdg_CM, rf_CM, gb_CM]\n",
    "    pr_AC = [knn_AC, rdg_AC, rf_AC, gb_AC]\n",
    "    pr_data = [pred_X, pred_y]\n",
    "\n",
    "    return (pr_RC, pr_CM, pr_AC, pr_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## run Netlogo and carryout ML\n",
    "knn_all_RC = []\n",
    "rdg_all_RC = []\n",
    "rf_all_RC = []\n",
    "gb_all_RC = []\n",
    "\n",
    "knn_all_CM = []\n",
    "rdg_all_CM = []\n",
    "rf_all_CM = []\n",
    "gb_all_CM = []\n",
    "\n",
    "knn_all_AC = []\n",
    "rdg_all_AC = []\n",
    "rf_all_AC = []\n",
    "gb_all_AC = []\n",
    "\n",
    "knn_all_cv_tr = []\n",
    "rdg_all_cv_tr = []\n",
    "rf_all_cv_tr = []\n",
    "gb_all_cv_tr = []\n",
    "\n",
    "knn_all_CM_tr = []\n",
    "rdg_all_CM_tr = []\n",
    "rf_all_CM_tr = []\n",
    "gb_all_CM_tr = []\n",
    "\n",
    "knn_all_RC_tr = []\n",
    "rdg_all_RC_tr = []\n",
    "rf_all_RC_tr = []\n",
    "gb_all_RC_tr = []\n",
    "\n",
    "knn_all_AC_tr = []\n",
    "rdg_all_AC_tr = []\n",
    "rf_all_AC_tr = []\n",
    "gb_all_AC_tr = []\n",
    "\n",
    "agentdata_tot = {}\n",
    "mobiledata_tot = {}\n",
    "traintestsplit_tot = {}\n",
    "pr_data_tot ={}\n",
    "traintestsplit = [None, None, None, None]\n",
    "\n",
    "ini_day = 0 # define the number of days to initiate the model (i.e. the original training data)\n",
    "\n",
    "last_n = 1 # define the number of days to be left out from simulation data for testing purpose\n",
    "tot_day = 100 # define the number of days to be simulated\n",
    "sim_day = 1 # define for one simulation how many days to be simulated\n",
    "#num_sim = 1440 # define the duration of simulation (in minutes)\n",
    "\n",
    "## initiating the model, \n",
    "model_init()\n",
    "\n",
    "## loop + prediction\n",
    "for x in range(0, tot_day, sim_day):\n",
    "    print x\n",
    "    currentday = x\n",
    "    sim_min = sim_day*1440\n",
    "    mob_call = \"repeat \" + str(sim_min) + \" [go]\" \n",
    "    run_NL(mob_call)\n",
    "    agentdata, mobiledata_ML = data_input()\n",
    "    train_classifier, train_CV, train_RC, train_CM, train_AC, traintestsplit = NL_ML(mobiledata_ML, currentday,\n",
    "                                                                                    traintestsplit)\n",
    "    pred_RC, pred_CM, pred_AC, pred_data = pred_agent(train_classifier, agentdata, last_n)\n",
    "    \n",
    "    agentdata_tot[x] = agentdata\n",
    "    mobiledata_tot[x] = mobiledata_ML\n",
    "    traintestsplit_tot[x] = traintestsplit\n",
    "    pr_data_tot[x] = pred_data\n",
    "    \n",
    "    knn_all_RC.append(pred_RC[0])\n",
    "    rdg_all_RC.append(pred_RC[1])\n",
    "    rf_all_RC.append(pred_RC[2])\n",
    "    gb_all_RC.append(pred_RC[3])\n",
    "    knn_all_CM.append(pred_CM[0])\n",
    "    rdg_all_CM.append(pred_CM[1])\n",
    "    rf_all_CM.append(pred_CM[2])\n",
    "    gb_all_CM.append(pred_CM[3])\n",
    "    knn_all_AC.append(pred_AC[0])\n",
    "    rdg_all_AC.append(pred_AC[1])\n",
    "    rf_all_AC.append(pred_AC[2])\n",
    "    gb_all_AC.append(pred_AC[3])\n",
    "    \n",
    "    knn_all_cv_tr.append(train_CV[0])\n",
    "    rdg_all_cv_tr.append(train_CV[1])\n",
    "    rf_all_cv_tr.append(train_CV[2])\n",
    "    gb_all_cv_tr.append(train_CV[3])\n",
    "    knn_all_CM_tr.append(train_CM[0])\n",
    "    rdg_all_CM_tr.append(train_CM[1])\n",
    "    rf_all_CM_tr.append(train_CM[2])\n",
    "    gb_all_CM_tr.append(train_CM[3])\n",
    "    knn_all_RC_tr.append(train_RC[0])\n",
    "    rdg_all_RC_tr.append(train_RC[1])\n",
    "    rf_all_RC_tr.append(train_RC[2])\n",
    "    gb_all_RC_tr.append(train_RC[3])\n",
    "    knn_all_AC_tr.append(train_AC[0])\n",
    "    rdg_all_AC_tr.append(train_AC[1])\n",
    "    rf_all_AC_tr.append(train_AC[2])\n",
    "    gb_all_AC_tr.append(train_AC[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rf_all_AC[99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pr_data_tot[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig3 = plt.figure(figsize=(10,5))\n",
    "ax = fig3.add_subplot(1, 1, 1)\n",
    "#ax.plot(mobiledata_fs['minute'][pd.notnull(mobiledata_fs['tzone'])], 'k.')\n",
    "#ax.plot(pd.notnull(mobiledata_fs['tzone']), 'k.')\n",
    "#ax.set_yticks([0, 1, 2])\n",
    "ax.plot(knn_all_AC, label='KNN', color=\"g\")\n",
    "ax.plot(rdg_all_AC, label='Ridge', color=\"b\")\n",
    "ax.plot(rf_all_AC, label='RF', color=\"y\")\n",
    "ax.plot(gb_all_AC, label='GBDT', color=\"r\")\n",
    "ax.set_yticks([0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "ax.set_ylabel(\"precision\")\n",
    "ax.set_xlabel(\"Number of days\")\n",
    "#ax.set_xticklabels(range(1,10))\n",
    "ax.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig3 = plt.figure(figsize=(10,5))\n",
    "ax = fig3.add_subplot(1, 1, 1)\n",
    "#ax.plot(mobiledata_fs['minute'][pd.notnull(mobiledata_fs['tzone'])], 'k.')\n",
    "#ax.plot(pd.notnull(mobiledata_fs['tzone']), 'k.')\n",
    "#ax.set_yticks([0, 1, 2])\n",
    "ax.plot(knn_all_AC_tr, label='KNN', color=\"g\")\n",
    "ax.plot(rdg_all_AC_tr, label='Ridge', color=\"b\")\n",
    "ax.plot(rf_all_AC_tr, label='RF', color=\"y\")\n",
    "ax.plot(gb_all_AC_tr, label='GBDT', color=\"r\")\n",
    "ax.set_yticks([0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "ax.set_ylabel(\"precision\")\n",
    "ax.set_xlabel(\"Number of days\")\n",
    "#ax.set_xticklabels(range(1,10))\n",
    "ax.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig3 = plt.figure(figsize=(10,5))\n",
    "ax = fig3.add_subplot(1, 1, 1)\n",
    "#ax.plot(mobiledata_fs['minute'][pd.notnull(mobiledata_fs['tzone'])], 'k.')\n",
    "#ax.plot(pd.notnull(mobiledata_fs['tzone']), 'k.')\n",
    "#ax.set_yticks([0, 1, 2])\n",
    "ax.plot(knn_all_RC, label='KNN', color=\"g\")\n",
    "ax.plot(rdg_all_RC, label='Ridge', color=\"b\")\n",
    "ax.plot(rf_all_RC, label='RF', color=\"y\")\n",
    "ax.plot(gb_all_RC, label='GBDT', color=\"r\")\n",
    "ax.set_yticks([0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "ax.set_ylabel(\"precision\")\n",
    "ax.set_xlabel(\"Call Frequency - number of calls per day\")\n",
    "#ax.set_xticklabels(range(1,10))\n",
    "ax.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig3 = plt.figure(figsize=(10,5))\n",
    "ax = fig3.add_subplot(1, 1, 1)\n",
    "#ax.plot(mobiledata_fs['minute'][pd.notnull(mobiledata_fs['tzone'])], 'k.')\n",
    "#ax.plot(pd.notnull(mobiledata_fs['tzone']), 'k.')\n",
    "#ax.set_yticks([0, 1, 2])\n",
    "ax.plot(knn_all_RC_tr, label='KNN', color=\"g\")\n",
    "ax.plot(rdg_all_RC_tr, label='Ridge', color=\"b\")\n",
    "ax.plot(rf_all_RC_tr, label='RF', color=\"y\")\n",
    "ax.plot(gb_all_RC_tr, label='GBDT', color=\"r\")\n",
    "ax.set_yticks([0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "ax.set_ylabel(\"precision\")\n",
    "ax.set_xlabel(\"Call Frequency - number of calls per day\")\n",
    "#ax.set_xticklabels(range(1,10))\n",
    "ax.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# checking the distribution of mobile phone calls\n",
    "fig2 = plt.figure(figsize=(10,5))\n",
    "ax = fig2.add_subplot(1, 1, 1)\n",
    "#ax.plot(mobiledata_fs['minute'][pd.notnull(mobiledata_fs['tzone'])], 'k.')\n",
    "#ax.plot(pd.notnull(mobiledata_fs['tzone']), 'k.')\n",
    "#ax.set_yticks([0, 1, 2])\n",
    "(mobiledata_ML['minute'][pd.notnull(mobiledata_ML['tzone'])]).hist(bins=12)\n",
    "#plt.hist(mobiledata_fs['minute'][pd.notnull(mobiledata_fs['tzone'])], bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,10))\n",
    "ax1 = fig.add_subplot(2, 2, 1)\n",
    "ax2 = fig.add_subplot(2, 2, 2)\n",
    "ax1.scatter(mobiledata_ML['minute'], mobiledata_ML['tzone'])\n",
    "ax1.set_xticks(range(0, 1440, 200))\n",
    "ax1.set_yticks(range(0, 45, 15))\n",
    "# ax2.plot(mobiledata_sel['minute'], mobiledata_sel['tzone_y'])\n",
    "# ax2.set_xticks(range(0, 1440, 200))\n",
    "# ax2.set_yticks(range(0, 45, 15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mobiledata_ML[mobiledata_ML['minute']==4]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "aa = agentdata[agentdata['day']==162]\n",
    "bb = agentdata[agentdata['day']==177]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print aa[aa['minute']==789], bb[bb['minute']==789]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class User(object):\n",
    "    def __init__(self, name, email):\n",
    "        self.name = name\n",
    "        self.email = email\n",
    "    def commit(self):\n",
    "        pass\n",
    "\n",
    "jason = User('jason', 'jason@email.com')\n",
    "jack = User('jack', 'jack@yahoo.com')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pr_data_tot[99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainX, testX, trainY, testY = traintestsplit_tot[99]\n",
    "pred_X, pred_y = pr_data_tot[99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#trainX.drop('acc_time', axis=1, inplace=True)\n",
    "trainX.drop('day', axis=1, inplace=True)\n",
    "#testX.drop('acc_time', axis=1, inplace=True)\n",
    "testX.drop('day', axis=1, inplace=True)\n",
    "#pred_X.drop('acc_time', axis=1, inplace=True)\n",
    "pred_X.drop('day', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## using RF\n",
    "clf_rf = RandomForestClassifier()#n_estimators=1000, max_depth=100)\n",
    "clf_rf.fit(trainX, trainY)\n",
    "pred_rf = clf_rf.predict(testX)\n",
    "print precision_score(testY, pred_rf, average=None)\n",
    "print accuracy_score(testY, pred_rf)\n",
    "print recall_score(testY, pred_rf, average='macro')\n",
    "print recall_score(testY, pred_rf, average='micro')\n",
    "print confusion_matrix(testY, pred_rf)\n",
    "\n",
    "pred_rf = clf_rf.predict(pred_X)\n",
    "print precision_score(pred_y, pred_rf, average=None)\n",
    "print accuracy_score(pred_y, pred_rf)\n",
    "print recall_score(pred_y, pred_rf, average='macro')\n",
    "print recall_score(pred_y, pred_rf, average='micro')\n",
    "print confusion_matrix(pred_y, pred_rf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# knn\n",
    "clf_knn = KNeighborsClassifier(n_neighbors=1).fit(trainX, trainY)\n",
    "pred_knn = clf_knn.predict(testX)\n",
    "#print roc_auc_score(testY, pred_knn)\n",
    "print precision_score(testY, pred_knn, average=None)\n",
    "print accuracy_score(testY, pred_knn)\n",
    "print recall_score(testY, pred_knn, average='macro')\n",
    "print recall_score(testY, pred_knn, average='micro')\n",
    "print confusion_matrix(testY, pred_knn)\n",
    "\n",
    "pred_knn = clf_knn.predict(pred_X)\n",
    "print precision_score(pred_y, pred_knn, average=None)\n",
    "print accuracy_score(pred_y, pred_knn)\n",
    "print recall_score(pred_y, pred_knn, average='macro')\n",
    "print recall_score(pred_y, pred_knn, average='micro')\n",
    "print confusion_matrix(pred_y, pred_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# knn\n",
    "clf_knn = KNeighborsClassifier(n_neighbors=1).fit(trainX, trainY)\n",
    "pred_knn = clf_knn.predict(testX)\n",
    "#print roc_auc_score(testY, pred_knn)\n",
    "print precision_score(testY, pred_knn, average=None)\n",
    "print accuracy_score(testY, pred_knn)\n",
    "print recall_score(testY, pred_knn, average='macro')\n",
    "print recall_score(testY, pred_knn, average='micro')\n",
    "print confusion_matrix(testY, pred_knn)\n",
    "\n",
    "pred_knn = clf_knn.predict(pred_X)\n",
    "print precision_score(pred_y, pred_knn, average=None)\n",
    "print accuracy_score(pred_y, pred_knn)\n",
    "print recall_score(pred_y, pred_knn, average='macro')\n",
    "print recall_score(pred_y, pred_knn, average='micro')\n",
    "print confusion_matrix(pred_y, pred_knn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path = './agentdata.txt'\n",
    "columnname = [\"todrop\", \"acc_time\", \"day\", \"minute\", \"pid\", \"zone\", \"status\", \"xcor\", \"ycor\", \"tid\"]\n",
    "agentdata = rawimport(path, columnname)\n",
    "\n",
    "path = './mobiletowers.txt'\n",
    "columnname = [\"todrop\", \"acc_time\", \"day\", \"minute\", \"pid\", \"tpid\", \"tzone\", \"radius\", \"tid\", \"txcor\", \"tycor\"]\n",
    "mobiledata = rawimport(path, columnname)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# leave the last n day(s) out for testing purpose\n",
    "\n",
    "#mobiledata_ML = mobiledata[mobiledata['day'] <= (mobiledata['day'].max() - last_n)]\n",
    "mobiledata_ML = mobiledata.drop('radius', axis = 1)\n",
    "mobiledata_ML.drop('tid', axis=1, inplace=True)\n",
    "mobiledata_ML.drop('txcor', axis=1, inplace=True)\n",
    "mobiledata_ML.drop('tycor', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prepare for ML\n",
    "X = mobiledata_ML.drop('tzone', axis=1)\n",
    "y = mobiledata_ML['tzone']\n",
    "trainX, testX, trainY, testY = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#k fold cross-validation\n",
    "from sklearn.cross_validation import KFold\n",
    "\n",
    "for train_indices, test_indices in KFold(len(X), n_folds=3):\n",
    "    fold_trainX = X.iloc[train_indices, :]\n",
    "    fold_testX  = X.iloc[test_indices, :]\n",
    "    fold_trainY = y[train_indices]\n",
    "    fold_testY  = y[test_indices]\n",
    "    clf_knn = KNeighborsClassifier(n_neighbors=2).fit(fold_trainX, fold_trainY)\n",
    "    pred_knn = clf_knn.predict(fold_testX)\n",
    "    #print roc_auc_score(testY, pred_knn)\n",
    "    print precision_score(fold_testY, pred_knn, average='micro')  \n",
    "    print recall_score(fold_testY, pred_knn, average='micro')\n",
    "    confusion_matrix(fold_testY, pred_knn)\n",
    "    #print fold_trainY\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# knn\n",
    "clf_knn = KNeighborsClassifier(n_neighbors=1).fit(trainX, trainY)\n",
    "pred_knn = clf_knn.predict(testX)\n",
    "#print roc_auc_score(testY, pred_knn)\n",
    "print precision_score(testY, pred_knn, average=None)\n",
    "print accuracy_score(testY, pred_knn)\n",
    "print recall_score(testY, pred_knn, average='macro')\n",
    "print recall_score(testY, pred_knn, average='micro')\n",
    "print confusion_matrix(testY, pred_knn)\n",
    "cross_val_score(clf_knn, X, y, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## using ridge regression\n",
    "clf_rdg = RidgeClassifier(alpha=1).fit(trainX,trainY)\n",
    "pred_rdg = clf_rdg.predict(testX)\n",
    "print precision_score(testY, pred_rdg, average='micro')  \n",
    "print confusion_matrix(testY, pred_rdg)\n",
    "cross_val_score(clf_rdg, X, y, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## using RF\n",
    "clf_rf = RandomForestClassifier(n_estimators=100, max_depth=100)\n",
    "clf_rf.fit(trainX, trainY)\n",
    "pred_rf = clf_rf.predict(testX)\n",
    "print precision_score(testY, pred_rf, average='micro')  \n",
    "print confusion_matrix(testY, pred_rf)\n",
    "cross_val_score(clf_rf, X, y, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## using GBDT\n",
    "clf_gb = GradientBoostingClassifier(n_estimators=100, max_depth=3)\n",
    "clf_gb.fit(trainX, trainY)\n",
    "pred_gb = clf_gb.predict(testX)\n",
    "print precision_score(testY, pred_gb, average='micro')  \n",
    "print confusion_matrix(testY, pred_gb)\n",
    "cross_val_score(clf_gb, X, y, cv=3)\n",
    "#test_qualities = []\n",
    "# for p in clf_gb.staged_predict_proba(testX):\n",
    "#     test_qualities.append(precision_score(testY, p[:, 1]))\n",
    "# plt.plot(test_qualities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "last_n = 1\n",
    "last_minutes = last_n * (-1440)\n",
    "pred_X = agentdata[last_minutes:].iloc[:,0:4]\n",
    "pred_X['tpid'] = 0\n",
    "pred_y = agentdata[last_minutes:].iloc[:,4]\n",
    "\n",
    "# pred_knn = trained_clf.clf1.predict(pred_X)\n",
    "# #print roc_auc_score(testY, pred_knn)\n",
    "# knn_AC = accuracy_score(pred_y, pred_knn)\n",
    "# knn_RC = recall_score(pred_y, pred_knn, average='macro')\n",
    "# knn_CM = confusion_matrix(pred_y, pred_knn)\n",
    "\n",
    "# ## using ridge regression\n",
    "# pred_rdg = trained_clf.clf2.predict(pred_X)\n",
    "# rdg_AC = accuracy_score(pred_y, pred_rdg)\n",
    "# rdg_RC = recall_score(pred_y, pred_rdg, average='macro')  \n",
    "# rdg_CM = confusion_matrix(pred_y, pred_rdg)\n",
    "\n",
    "# ## using RF\n",
    "# pred_rf = trained_clf.clf3.predict(pred_X)\n",
    "# rf_AC = accuracy_score(pred_y, pred_rf)\n",
    "# rf_RC = recall_score(pred_y, pred_rf, average='macro')  \n",
    "# rf_CM = confusion_matrix(pred_y, pred_rf)\n",
    "\n",
    "## using GBDT\n",
    "pred_gb = clf_gb.predict(pred_X)\n",
    "gb_AC = accuracy_score(pred_y, pred_gb)\n",
    "gb_RC = recall_score(pred_y, pred_gb, average='macro')  \n",
    "gb_CM = confusion_matrix(pred_y, pred_gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gb_CM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## using SVM\n",
    "## solving multi-classification problem?\n",
    "clf_svc = SVC()\n",
    "clf_svc.fit(trainX, trainY)\n",
    "pred_svc = clf_svc.predict(testX)\n",
    "print precision_score(testY, pred_svc, average='micro')  \n",
    "print confusion_matrix(testY, pred_svc)\n",
    "cross_val_score(clf_svc, X, y, cv=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## prediction\n",
    "# pre_agent1 = mobiledata[:1]\n",
    "# pre_agent = pd.concat([pre_agent1]*1440)\n",
    "# pre_agent['day']=mobiledata['day'].max()+1\n",
    "# pre_agent['minute']=range(0,1440)\n",
    "# pre_agent['acc_time']=pre_agent['minute'] + pre_agent['day']*1440\n",
    "# pre_agent.drop('tzone', axis=1, inplace=True)\n",
    "# pre_agent.drop('radius', axis=1, inplace=True)\n",
    "# pre_agent.drop('tid', axis=1, inplace=True)\n",
    "# pre_agent.drop('txcor', axis=1, inplace=True)\n",
    "# pre_agent.drop('tycor', axis=1, inplace=True)\n",
    "pred_X = agentdata[-1440:].iloc[:,0:4]\n",
    "pred_X['tpid'] = 0\n",
    "pred_y = agentdata[-1440:].iloc[:,4]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "pred_knn = clf_knn.predict(pred_X)\n",
    "#print roc_auc_score(testY, pred_knn)\n",
    "knn_PR = precision_score(pred_y, pred_knn, average='micro')\n",
    "knn_CM = confusion_matrix(pred_y, pred_knn)\n",
    "\n",
    "## using ridge regression\n",
    "pred_rdg = clf_rdg.predict(pred_X)\n",
    "rdg_PR = precision_score(pred_y, pred_rdg, average='micro')  \n",
    "rdg_CM = confusion_matrix(pred_y, pred_rdg)\n",
    "\n",
    "## using RF\n",
    "pred_rf = clf_rf.predict(pred_X)\n",
    "rf_PR = precision_score(pred_y, pred_rf, average='micro')  \n",
    "rf_CM = confusion_matrix(pred_y, pred_rf)\n",
    "\n",
    "## using GBDT\n",
    "pred_gb = clf_gb.predict(pred_X)\n",
    "gb_PR = precision_score(pred_y, pred_gb, average='micro')  \n",
    "gb_CM = confusion_matrix(pred_y, pred_gb)\n",
    "\n",
    "print knn_PR, rdg_PR, rf_PR, gb_PR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred_gb\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pre_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prepare for ML\n",
    "X = mobiledata_fs_filled.drop('zone', axis=1)\n",
    "y = mobiledata_fs_filled['zone']\n",
    "trainX, testX, trainY, testY = train_test_split(X, y)\n",
    "\n",
    "## using KNN\n",
    "# weights might need to be changed - more weights towards the recent data?\n",
    "# metrics? canberra, minkowski\n",
    "clf_knn = KNeighborsClassifier(n_neighbors=1).fit(trainX, trainY)\n",
    "pred_knn = clf_knn.predict(testX)\n",
    "#print roc_auc_score(testY, pred_knn)\n",
    "knn_PR = precision_score(testY, pred_knn, average='micro')\n",
    "knn_CM = confusion_matrix(testY, pred_knn)\n",
    "\n",
    "## using ridge regression\n",
    "clf_rdg = RidgeClassifier(alpha=1).fit(trainX,trainY)\n",
    "pred_rdg = clf_rdg.predict(testX)\n",
    "rdg_PR = precision_score(testY, pred_rdg, average='micro')  \n",
    "rdg_CM = confusion_matrix(testY, pred_rdg)\n",
    "\n",
    "## using RF\n",
    "clf_rf = RandomForestClassifier(n_estimators=100, max_depth=10)\n",
    "clf_rf.fit(trainX, trainY)\n",
    "pred_rf = clf_rf.predict(testX)\n",
    "rf_PR = precision_score(testY, pred_rf, average='micro')  \n",
    "rf_CM = confusion_matrix(testY, pred_rf)\n",
    "\n",
    "## using GBDT\n",
    "clf_gb = GradientBoostingClassifier(n_estimators=100, max_depth=3)\n",
    "clf_gb.fit(trainX, trainY)\n",
    "pred_gb = clf_gb.predict(testX)\n",
    "gb_PR = precision_score(testY, pred_gb, average='micro')  \n",
    "gb_CM = confusion_matrix(testY, pred_gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#class ReturnValue(object):\n",
    "#    def __init__(self, y0, y1):\n",
    "#        self.y0 = y0\n",
    "#        self.y1 = y1\n",
    "\n",
    "def data_input():\n",
    "    path = './agentdata.txt'\n",
    "    columnname = [\"todrop\", \"acc_time\", \"day\", \"minute\", \"pid\", \"zone\", \"status\", \"xcor\", \"ycor\", \"tid\"]\n",
    "    agentdata = rawimport(path, columnname)\n",
    "    \n",
    "    path = './mobiletowers.txt'\n",
    "    columnname = [\"todrop\", \"acc_time\", \"day\", \"minute\", \"pid\", \"tpid\", \"tzone\", \"radius\", \"tid\", \"txcor\", \"tycor\"]\n",
    "    mobiledata = rawimport(path, columnname)\n",
    "    \n",
    "    # extend data to full (missing data shown as NaN)\n",
    "    mobiledata = mobiledata.drop(labels = [\"tid\"], axis=1)\n",
    "\n",
    "    mobiledata_fs = pd.merge(agentdata, mobiledata, how = 'left', on = [\"acc_time\", 'day', 'minute', \"pid\"])\n",
    "    #mobiledata_fs = pd.merge(agentdata_ri, mobiledata_ri, how = 'left', left_index = True, right_index = True)\n",
    "    #print mobiledata_fs.count()\n",
    "    #mobiledata_fs\n",
    "# fill the missing data using NN (k=1)\n",
    "# the reason why \"day\" and \"minute\" need to be removed before imputation is that the imputation is done based on features.\n",
    "# in other words, the day and minute will have impacts on the imputed results\n",
    "# to maintain a continuity of a user between days it is necessary to remove \"day\" and \"minute\" before imputation and add them back later\n",
    "# also no need to imputate tower id\n",
    "    mobiledata_fs_test = mobiledata_fs.drop(labels = [\"day\"], axis=1)\n",
    "    mobiledata_fs_test = mobiledata_fs_test.drop(labels = [\"minute\"], axis=1)\n",
    "    mobiledata_fs_test = mobiledata_fs_test.drop(labels = [\"tid\"], axis=1)\n",
    "    mobiledata_fs_filled = KNN(k=1).complete(mobiledata_fs_test)\n",
    "    mobiledata_fs_filled = pd.DataFrame(mobiledata_fs_filled, columns = [\"acc_time\", \"pid\", \"zone\", \n",
    "                                                                     \"status\", \"xcor\", \"ycor\", \"tpid\", \"tzone\", \n",
    "                                                                     \"radius\", \"txcor\", \"tycor\"])\n",
    "# add the day and minute information back\n",
    "    mobiledata_daymin = mobiledata_fs.ix[:,[0, 1, 2, 3, 8]]\n",
    "    mobiledata_fs_filled = pd.merge(mobiledata_daymin, mobiledata_fs_filled, how = 'left', on = [\"acc_time\", \"pid\"])\n",
    "    mobiledata_cp = pd.merge(mobiledata_fs, mobiledata_fs_filled, how = 'left', on = [\"acc_time\", 'day', 'minute', \"pid\"])\n",
    "    mobiledata_fs_filled.fillna(-1, inplace=True)\n",
    "    \n",
    "    return (mobiledata_fs, mobiledata_fs_filled, mobiledata_cp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#run_NL()\n",
    "\n",
    "mobiledata_fs, mobiledata_fs_filled, mobiledata_cp = data_input()\n",
    "#miss_imput()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print mobiledata_fs_filled.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mobiledata_fs_filled.zone.max()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,10))\n",
    "ax1 = fig.add_subplot(2, 2, 1)\n",
    "ax2 = fig.add_subplot(2, 2, 2)\n",
    "mobiledata_sel = mobiledata_cp[mobiledata_cp['day'] == 0]\n",
    "ax1.scatter(mobiledata_sel['minute'], mobiledata_sel['tzone_x'])\n",
    "ax1.set_xticks(range(0, 1440, 200))\n",
    "ax1.set_yticks(range(0, 45, 15))\n",
    "ax2.plot(mobiledata_sel['minute'], mobiledata_sel['tzone_y'])\n",
    "ax2.set_xticks(range(0, 1440, 200))\n",
    "ax2.set_yticks(range(0, 45, 15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# checking the distribution of mobile phone calls\n",
    "fig2 = plt.figure(figsize=(10,5))\n",
    "ax = fig2.add_subplot(1, 1, 1)\n",
    "#ax.plot(mobiledata_fs['minute'][pd.notnull(mobiledata_fs['tzone'])], 'k.')\n",
    "#ax.plot(pd.notnull(mobiledata_fs['tzone']), 'k.')\n",
    "#ax.set_yticks([0, 1, 2])\n",
    "(mobiledata_fs['minute'][pd.notnull(mobiledata_fs['tzone'])]).hist(bins=12)\n",
    "#plt.hist(mobiledata_fs['minute'][pd.notnull(mobiledata_fs['tzone'])], bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ML\n",
    "def NL_ML(mobiledata_fs_filled):\n",
    "    # prepare for ML\n",
    "    X = mobiledata_fs_filled.drop('zone', axis=1)\n",
    "    y = mobiledata_fs_filled['zone']\n",
    "    trainX, testX, trainY, testY = train_test_split(X, y)\n",
    "    \n",
    "    ## using KNN\n",
    "    # weights might need to be changed - more weights towards the recent data?\n",
    "    # metrics? canberra, minkowski\n",
    "    clf_knn = KNeighborsClassifier(n_neighbors=1).fit(trainX, trainY)\n",
    "    pred_knn = clf_knn.predict(testX)\n",
    "    #print roc_auc_score(testY, pred_knn)\n",
    "    knn_PR = precision_score(testY, pred_knn, average='micro')\n",
    "    knn_CM = confusion_matrix(testY, pred_knn)\n",
    "    \n",
    "    ## using ridge regression\n",
    "    clf_rdg = RidgeClassifier(alpha=1).fit(trainX,trainY)\n",
    "    pred_rdg = clf_rdg.predict(testX)\n",
    "    rdg_PR = precision_score(testY, pred_rdg, average='micro')  \n",
    "    rdg_CM = confusion_matrix(testY, pred_rdg)\n",
    "    \n",
    "    ## using RF\n",
    "    clf_rf = RandomForestClassifier(n_estimators=100, max_depth=10)\n",
    "    clf_rf.fit(trainX, trainY)\n",
    "    pred_rf = clf_rf.predict(testX)\n",
    "    rf_PR = precision_score(testY, pred_rf, average='micro')  \n",
    "    rf_CM = confusion_matrix(testY, pred_rf)\n",
    "    \n",
    "    ## using GBDT\n",
    "    clf_gb = GradientBoostingClassifier(n_estimators=100, max_depth=3)\n",
    "    clf_gb.fit(trainX, trainY)\n",
    "    pred_gb = clf_gb.predict(testX)\n",
    "    gb_PR = precision_score(testY, pred_gb, average='micro')  \n",
    "    gb_CM = confusion_matrix(testY, pred_gb)\n",
    "    \n",
    "    return (knn_PR, knn_CM, rdg_PR, rdg_CM, rf_PR, rf_CM, gb_PR, gb_CM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig3 = plt.figure(figsize=(10,5))\n",
    "ax = fig3.add_subplot(1, 1, 1)\n",
    "#ax.plot(mobiledata_fs['minute'][pd.notnull(mobiledata_fs['tzone'])], 'k.')\n",
    "#ax.plot(pd.notnull(mobiledata_fs['tzone']), 'k.')\n",
    "#ax.set_yticks([0, 1, 2])\n",
    "ax.plot(knn_all_PR, label='NN', color=\"g\")\n",
    "ax.plot(rdg_all_PR, label='Ridge', color=\"b\")\n",
    "ax.plot(rf_all_PR, label='RF', color=\"y\")\n",
    "ax.plot(gb_all_PR, label='GBDT', color=\"r\")\n",
    "ax.set_yticks([0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "ax.set_ylabel(\"precision\")\n",
    "ax.set_xlabel(\"Call Frequency - number of calls per day\")\n",
    "ax.set_xticklabels(range(1,10))\n",
    "ax.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "knn_all_PR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t = NL_ML(comdata_fs_filled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print gb_all_PR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# prepare for ML\n",
    "\n",
    "X = mobiledata_fs_filled.drop('zone', axis=1)\n",
    "y = mobiledata_fs_filled['zone']\n",
    "\n",
    "trainX, testX, trainY, testY = train_test_split(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## using KNN\n",
    "# weights might need to be changed - more weights towards the recent data?\n",
    "# metrics? canberra, minkowski\n",
    "\n",
    "\n",
    "clf_knn = KNeighborsClassifier(n_neighbors=1).fit(trainX, trainY)\n",
    "pred_knn = clf_knn.predict(testX)\n",
    "#print roc_auc_score(testY, pred_knn)\n",
    "print precision_score(testY, pred_knn, average='micro')  \n",
    "print recall_score(testY, pred_knn, average='micro')\n",
    "confusion_matrix(testY, pred_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred_knn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testX, pred_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## using Ridge\n",
    "\n",
    "clf_rdg = RidgeClassifier(alpha=1).fit(trainX,trainY)\n",
    "pred_rdg = clf_rdg.predict(testX)\n",
    "print precision_score(testY, pred_rdg, average='micro')  \n",
    "print recall_score(testY, pred_rdg, average='micro')\n",
    "confusion_matrix(testY, pred_rdg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## using Lasso\n",
    "\n",
    "clf_las = Lasso(alpha=1).fit(trainX,trainY)\n",
    "pred_las = clf_las.predict(testX)\n",
    "print precision_score(testY, pred_las, average='micro')  \n",
    "print recall_score(testY, pred_las, average='micro')\n",
    "confusion_matrix(testY, pred_las)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## using RF\n",
    "\n",
    "clf_rf = RandomForestClassifier(n_estimators=100, max_depth=10)\n",
    "clf_rf.fit(trainX, trainY)\n",
    "pred_rf = clf_rf.predict(testX)\n",
    "print precision_score(testY, pred_rf, average='micro')  \n",
    "print recall_score(testY, pred_rf, average='micro')\n",
    "confusion_matrix(testY, pred_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## using GBDT\n",
    "\n",
    "clf_gb = GradientBoostingClassifier(n_estimators=100, max_depth=3)\n",
    "clf_gb.fit(trainX, trainY)\n",
    "pred_gb = clf_gb.predict(testX)\n",
    "print precision_score(testY, pred_gb, average='micro')  \n",
    "print recall_score(testY, pred_gb, average='micro')\n",
    "confusion_matrix(testY, pred_gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# neural network\n",
    "def fit_predict_NN(trainX, trainY, testX, activate_functions, hidden_layers):\n",
    "    X_ = theano.shared(trainX, name='X')\n",
    "    y_ = theano.shared(trainY, name='y')\n",
    "    param = T.vector()\n",
    "    dim = X.shape[1]\n",
    "    \n",
    "    def activation(data_, parameter):\n",
    "        n_previous = 0\n",
    "        dim_previous = dim\n",
    "        h = data_\n",
    "        for n_hidden, func in zip(hidden_layers, activate_functions):\n",
    "            N = dim_previous * n_hidden\n",
    "            W_ = parameter[n_previous:n_previous + N].reshape((dim_previous, n_hidden))\n",
    "            h = func(h.dot(W_))\n",
    "            dim_previous = n_hidden\n",
    "            n_previous += N\n",
    "\n",
    "        # output     \n",
    "        v_ = parameter[n_previous:]\n",
    "        output = h.dot(v_)\n",
    "        n_previous = n_previous + dim_previous\n",
    "        \n",
    "        return T.nnet.sigmoid(output), n_previous\n",
    "\n",
    "    p_sig = activation(X_, param)[0]\n",
    "    p_bck = 1 - p_sig\n",
    "    llh_ = y_.dot(T.log(p_sig)) + (1 - y_).dot(T.log(p_bck))\n",
    "    loss = -llh_\n",
    "    \n",
    "    # optimize\n",
    "    loss_function = theano.function([param], loss)\n",
    "    loss_grad = theano.function([param], theano.grad(loss, param))\n",
    "    result = minimize(loss_function, jac=loss_grad, x0=numpy.random.normal(size=activation(X_, param)[1]))\n",
    "    optimal_params = result['x']\n",
    "    \n",
    "    # predict data\n",
    "    data = T.matrix()\n",
    "    compiled_activation = theano.function([data, param], activation(data, param)[0])\n",
    "    \n",
    "    return compiled_activation(testX, optimal_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## define activation function\n",
    "#sigmoid (which we used, T.nnet.sigmoid)\n",
    "#leaky ReLU (defined below)\n",
    "#softplus (T.nnet.softplus)\n",
    "\n",
    "def LeakyReLU(x):\n",
    "    return T.switch(x > 0, x, 0.5 * x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred = fit_predict_NN(trainX, trainY, testX, [T.nnet.sigmoid] * 3, [20, 10, 5])\n",
    "print precision_score(testY, pred, average='micro')  \n",
    "print recall_score(testY, pred, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import theano\n",
    "A = np.random.rand(1000,10000).astype(theano.config.floatX)\n",
    "B = np.random.rand(10000,1000).astype(theano.config.floatX)\n",
    "np_start = time.time()\n",
    "AB = A.dot(B)\n",
    "np_end = time.time()\n",
    "X,Y = theano.tensor.matrices('XY')\n",
    "mf = theano.function([X,Y],X.dot(Y))\n",
    "t_start = time.time()\n",
    "tAB = mf(A,B)\n",
    "t_end = time.time()\n",
    "print(\"NP time: %f[s], theano time: %f[s] (times should be close when run on CPU!)\" %(\n",
    "                                           np_end-np_start, t_end-t_start))\n",
    "print(\"Result difference: %f\" % (np.abs(AB-tAB).max(), ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
