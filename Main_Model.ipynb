{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import functions\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import codecs\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler                 #normalising features\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.cross_validation import KFold\n",
    "\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.svm import SVC, SVR\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor\n",
    "from sknn import mlp\n",
    "\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed=10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "# Generating population\n",
    "% time\n",
    "num_pop = 100     #number of population\n",
    "num_date = 100    #number of days to be simulated\n",
    "num_time = 24     #time intervals; 24 for hourly data, 96 for 15min data; 1440 for 1min data\n",
    "\n",
    "hist_data = []\n",
    "# pd.DataFrame(columns=['personID', 'income', 'employment', 'children', 'Date', 'time', 'zone'])\n",
    "\n",
    "\n",
    "for npop in range(num_pop):\n",
    "    income = np.random.normal(loc=25000, scale=5000)\n",
    "    employment = np.random.randint(0, 5)  #assuming 4 types of employment; 0: full-time; 1: part-time; 2: students; 3: unemployed\n",
    "    children = np.random.randint(0, 2)    #0 - no children or 1 - have children\n",
    "    for ndate in range(num_date):\n",
    "        for ntime in range(num_time):\n",
    "            zone = np.random.randint(0,50)  #number of zones, assuming 50\n",
    "            hist_data.append([npop, income, employment, children, ndate, ntime, zone])\n",
    "        \n",
    "hist_data = pd.DataFrame(hist_data, columns=['personID', 'income', 'employment', 'children', 'date', 'time', 'zone'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# making predictions\n",
    "\n",
    "X = hist_data.drop('zone', axis=1)\n",
    "y = hist_data['zone']\n",
    "\n",
    "trainX, testX, trainY, testY = train_test_split(X, y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01915\n",
      "0.01915\n",
      "0.02\n"
     ]
    }
   ],
   "source": [
    "## using KNN\n",
    "# weights might need to be changed - more weights towards the recent data?\n",
    "# metrics? canberra, minkowski\n",
    "\n",
    "clf_knn = KNeighborsClassifier(n_neighbors=1).fit(trainX, trainY)\n",
    "pred_knn = clf_knn.predict_proba(testX)[:, 1]\n",
    "print precision_score(testY, pred_knn, average='micro')  \n",
    "print recall_score(testY, pred_knn, average='micro')\n",
    "print 1./50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0193166666667\n",
      "0.0193166666667\n"
     ]
    }
   ],
   "source": [
    "## using Ridge\n",
    "\n",
    "clf_rdg = RidgeClassifier(alpha=1).fit(trainX,trainY)\n",
    "pred_rdg = clf_rdg.predict(testX)\n",
    "print precision_score(testY, pred_rdg, average='micro')  \n",
    "print recall_score(testY, pred_rdg, average='micro')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## using Lasso\n",
    "\n",
    "clf_las = Lasso(alpha=1).fit(trainX,trainY)\n",
    "pred_las = clf_las.predict(testX)\n",
    "print precision_score(testY, pred_las, average='micro')  \n",
    "print recall_score(testY, pred_las, average='micro')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0198666666667\n",
      "0.0198666666667\n",
      "0.02\n"
     ]
    }
   ],
   "source": [
    "## using RF\n",
    "\n",
    "clf_rf = RandomForestClassifier(n_estimators=100, max_depth=10)\n",
    "clf_rf.fit(trainX, trainY)\n",
    "pred_rf = clf_rf.predict(testX)\n",
    "print precision_score(testY, pred_rf, average='micro')  \n",
    "print recall_score(testY, pred_rf, average='micro')\n",
    "print 1./50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0187666666667\n",
      "0.0187666666667\n",
      "0.02\n"
     ]
    }
   ],
   "source": [
    "## using GBDT\n",
    "\n",
    "clf_gb = GradientBoostingClassifier(n_estimators=100, max_depth=3)\n",
    "clf_gb.fit(trainX, trainY)\n",
    "pred_gb = clf_gb.predict(testX)\n",
    "print precision_score(testY, pred_gb, average='micro')  \n",
    "print recall_score(testY, pred_gb, average='micro')\n",
    "print 1./50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## using NN\n",
    "\n",
    "clf_nn = mlp.Classifier(layers=[mlp.Layer(\"Sigmoid\", units=100), mlp.Layer(\"Softmax\")], n_iter=25)\n",
    "clf_nn.fit(trainX, trainY)\n",
    "pred_nn = clf_nn.predict(testX)\n",
    "print precision_score(testY, pred_nn, average='micro')  \n",
    "print recall_score(testY, pred_nn, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# neural network\n",
    "def fit_predict_NN(trainX, trainY, testX, activate_functions, hidden_layers):\n",
    "    X_ = theano.shared(trainX, name='X')\n",
    "    y_ = theano.shared(trainY, name='y')\n",
    "    param = T.vector()\n",
    "    dim = X.shape[1]\n",
    "    \n",
    "    def activation(data_, parameter):\n",
    "        n_previous = 0\n",
    "        dim_previous = dim\n",
    "        h = data_\n",
    "        for n_hidden, func in zip(hidden_layers, activate_functions):\n",
    "            N = dim_previous * n_hidden\n",
    "            W_ = parameter[n_previous:n_previous + N].reshape((dim_previous, n_hidden))\n",
    "            h = func(h.dot(W_))\n",
    "            dim_previous = n_hidden\n",
    "            n_previous += N\n",
    "\n",
    "        # output     \n",
    "        v_ = parameter[n_previous:]\n",
    "        output = h.dot(v_)\n",
    "        n_previous = n_previous + dim_previous\n",
    "        \n",
    "        return T.nnet.sigmoid(output), n_previous\n",
    "\n",
    "    p_sig = activation(X_, param)[0]\n",
    "    p_bck = 1 - p_sig\n",
    "    llh_ = y_.dot(T.log(p_sig)) + (1 - y_).dot(T.log(p_bck))\n",
    "    loss = -llh_\n",
    "    \n",
    "    # optimize\n",
    "    loss_function = theano.function([param], loss)\n",
    "    loss_grad = theano.function([param], theano.grad(loss, param))\n",
    "    result = minimize(loss_function, jac=loss_grad, x0=numpy.random.normal(size=activation(X_, param)[1]))\n",
    "    optimal_params = result['x']\n",
    "    \n",
    "    # predict data\n",
    "    data = T.matrix()\n",
    "    compiled_activation = theano.function([data, param], activation(data, param)[0])\n",
    "    \n",
    "    return compiled_activation(testX, optimal_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## define activation function\n",
    "#sigmoid (which we used, T.nnet.sigmoid)\n",
    "#leaky ReLU (defined below)\n",
    "#softplus (T.nnet.softplus)\n",
    "\n",
    "def LeakyReLU(x):\n",
    "    return T.switch(x > 0, x, 0.5 * x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = fit_predict_NN(trainX, trainY, testX, [LeakyReLU] * 3, [20, 10, 5])\n",
    "print precision_score(testY, pred_gb, average='micro')  \n",
    "print recall_score(testY, pred_gb, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.17'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 'spam']\n",
      "[(1, 2)]\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "\n",
    "G=nx.Graph()\n",
    "G.add_node(\"spam\")\n",
    "G.add_edge(1,2)\n",
    "print(G.nodes())\n",
    "#[1, 2, 'spam']\n",
    "print(G.edges())\n",
    "#[(1, 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(8.0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "x = T.vector('x')\n",
    "A = T.matrix('A')\n",
    "z = A.dot(x)\n",
    "normAx = theano.function([x, A], z.dot(z))\n",
    "normAx([0, 2], [[1, 1], [1, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mpl_toolkits.basemap import Basemap\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
